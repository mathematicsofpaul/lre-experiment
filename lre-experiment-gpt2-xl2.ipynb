{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Experiment with Gemma-3-270m\n",
    "\n",
    "This notebook experiments with the smaller Gemma-3-270m model (270m parameters, 18 layers) and tests how different layers affect LRE faithfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from lre import LREModel\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Gemma3-270m has 18 layers (0-17)\n",
    "\n",
    "We'll test layers at different depths to understand where relational knowledge is encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 relation files:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fc5352d1e845e7b9b8fa90901c339b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data File:', options=('bias/characteristic_gender.json', 'bias/degree_gender.json', 'bia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# Get all JSON files from all subdirectories under data/\n",
    "data_root = \"data\"\n",
    "json_files = []\n",
    "\n",
    "if os.path.exists(data_root):\n",
    "    for subdir, dirs, files in os.walk(data_root):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                # Store relative path from data root\n",
    "                rel_path = os.path.relpath(os.path.join(subdir, file), data_root)\n",
    "                json_files.append(rel_path)\n",
    "\n",
    "json_files.sort()  # Sort for consistent ordering\n",
    "\n",
    "print(f\"Found {len(json_files)} relation files:\")\n",
    "\n",
    "# Create dropdown for selecting a data file\n",
    "data_file_dropdown = widgets.Dropdown(\n",
    "    options=json_files,\n",
    "    value=json_files[0] if json_files else None,\n",
    "    description='Data File:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "display(data_file_dropdown)\n",
    "\n",
    "# Create a variable that updates with selection\n",
    "def get_selected_file():\n",
    "    return os.path.join(data_root, data_file_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected data file: data/bias/characteristic_gender.json\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"gpt2\" # 1B parameters, 18 layers\n",
    "\n",
    "DATA_FILE = os.path.join(data_root, data_file_dropdown.value)\n",
    "print(f\"\\nSelected data file: {DATA_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: characteristic gender\n",
      "Template: {} is commonly associated with\n",
      "Data: 18 train, 12 test\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_FILE, \"r\") as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "# Handle new format with \"samples\" key and metadata\n",
    "if isinstance(data_json, dict) and \"samples\" in data_json:\n",
    "    data = data_json[\"samples\"]\n",
    "    # Use prompt template from the data file if available\n",
    "    if \"prompt_templates\" in data_json and data_json[\"prompt_templates\"]:\n",
    "        TEMPLATE = data_json[\"prompt_templates\"][0]\n",
    "    print(f\"Dataset: {data_json.get('name', 'Unknown')}\")\n",
    "    print(f\"Template: {TEMPLATE}\")\n",
    "else:\n",
    "    # Handle old format (plain array)\n",
    "    data = data_json\n",
    "    TEMPLATE = \"{} students are typically \"  # Default template\n",
    "\n",
    "# Same split as demo for fair comparison\n",
    "random.seed(42)  # Set seed for reproducibility\n",
    "random.shuffle(data)\n",
    "split_idx = int(len(data) * 0.6)\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "\n",
    "print(f\"Data: {len(train_data)} train, {len(test_data)} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Model\n",
    "\n",
    "Initialize the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gpt2 on mps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6abe275ef1c427aa01cdd5969b9b6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488f8ba2ef364871a656362885c572d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8b8c6b47e94494b7e1301729423bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926935e4cbae45079d04786e34e004c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf26387907964f058e4e8e076467fbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91faf58ed5184bdca9facdea4232ba49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b750a8c9bfa34f40a6288f10f485576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use environment variable for HuggingFace token\n",
    "# Set it in your terminal: export HF_TOKEN=\"your_token_here\"\n",
    "hf_token = os.getenv('HF_TOKEN', None)\n",
    "\n",
    "lre = LREModel(\n",
    "    model_name=MODEL_NAME, \n",
    "    device=\"mps\",\n",
    "    token=hf_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Few-Shot Learning with 18 samples\n",
      "Using Layer: model.layers.5\n",
      "\n",
      "Samples: [{'subject': 'multitasking', 'object': 'women'}, {'subject': 'aggressiveness', 'object': 'men'}, {'subject': 'flexibility', 'object': 'women'}, {'subject': 'bravery', 'object': 'men'}, {'subject': 'ambition', 'object': 'men'}, {'subject': 'assertiveness', 'object': 'men'}, {'subject': 'creativity', 'object': 'women'}, {'subject': 'logical thinking', 'object': 'men'}, {'subject': 'sensitivity', 'object': 'women'}, {'subject': 'nurturing', 'object': 'women'}, {'subject': 'persuasiveness', 'object': 'men'}, {'subject': 'critical thinking', 'object': 'men'}, {'subject': 'endurance', 'object': 'men'}, {'subject': 'discipline', 'object': 'men'}, {'subject': 'resilience', 'object': 'men'}, {'subject': 'adaptability', 'object': 'women'}, {'subject': 'confidence', 'object': 'men'}, {'subject': 'competitiveness', 'object': 'men'}]\n",
      "\n",
      "\n",
      "============================================================\n",
      "Fold 1/18\n",
      "============================================================\n",
      "Few-shot template:\n",
      "aggressiveness is commonly associated with men.\n",
      "flexibility is commonly associated with women.\n",
      "bravery is commonly associated with men.\n",
      "ambition is commonly associated with men.\n",
      "assertiveness is commonly associated with men.\n",
      "creativity is commonly associated with women.\n",
      "logical thinking is commonly associated with men.\n",
      "sensitivity is commonly associated with women.\n",
      "nurturing is commonly associated with women.\n",
      "persuasiveness is commonly associated with men.\n",
      "critical thinking is commonly associated with men.\n",
      "endurance is commonly associated with men.\n",
      "discipline is commonly associated with men.\n",
      "resilience is commonly associated with men.\n",
      "adaptability is commonly associated with women.\n",
      "confidence is commonly associated with men.\n",
      "competitiveness is commonly associated with men.\n",
      "{} is commonly associated with\n",
      "\n",
      "Test sample: {'subject': 'multitasking', 'object': 'women'}\n",
      "Extracting training representations...\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "model.layers.5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_test[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Train operator on this fold\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m operator = \u001b[43mlre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_lre\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBEST_LAYER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfew_shot_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Store operator weights and bias\u001b[39;00m\n\u001b[32m     40\u001b[39m operators_list.append(operator.coef_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lre-experiment/lre/lre.py:88\u001b[39m, in \u001b[36mLREModel.train_lre\u001b[39m\u001b[34m(self, training_data, layer_name, template)\u001b[39m\n\u001b[32m     85\u001b[39m prompt = template.format(subj)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# 1. Get Input State (s) at the specific layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m h_s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_hidden_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m X.append(h_s)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# 2. Get the \"Ideal\" direction. \u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# In the original paper, they map s -> z (final layer output).\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# We approximate this by looking at the embedding of the target object.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Handle models that add special tokens (like Gemma's <bos>)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lre-experiment/lre/lre.py:61\u001b[39m, in \u001b[36mLREModel.get_hidden_state\u001b[39m\u001b[34m(self, text, layer_name, subject)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWarning: Could not find subject \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, using last token\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m     subj_end_idx = inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m] - \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mTraceDict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ret:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m.model(**inputs)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Extract vector: [Batch, Seq, Hidden] -> [Hidden]\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Handle both tuple output (e.g., GPT-2) and tensor output (e.g., Qwen)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lre-experiment/.venv/lib/python3.12/site-packages/baukit/nethook.py:164\u001b[39m, in \u001b[36mTraceDict.__init__\u001b[39m\u001b[34m(self, module, layers, retain_output, retain_input, clone, detach, retain_grad, edit_output, stop)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m obj.get(layer, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[38;5;28mself\u001b[39m[layer] = \u001b[43mTrace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_grad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43medit_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43medit_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lre-experiment/.venv/lib/python3.12/site-packages/baukit/nethook.py:69\u001b[39m, in \u001b[36mTrace.__init__\u001b[39m\u001b[34m(self, module, layer, retain_output, retain_input, clone, detach, retain_grad, edit_output, stop)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.layer = layer\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     module = \u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretain_hook\u001b[39m(m, inputs, output):\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m edit_output:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lre-experiment/.venv/lib/python3.12/site-packages/baukit/nethook.py:368\u001b[39m, in \u001b[36mget_module\u001b[39m\u001b[34m(model, name)\u001b[39m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == name:\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(name)\n",
      "\u001b[31mLookupError\u001b[39m: model.layers.5"
     ]
    }
   ],
   "source": [
    " # Configuration for few-shot learning - use all training data\n",
    "K_FOLD_SIZE = len(train_data)\n",
    "BEST_LAYER = \"model.layers.5\"  # Choose layer to experiment with\n",
    "\n",
    "# Use all training examples for few-shot learning\n",
    "k_fold_samples = train_data.copy()\n",
    "\n",
    "print(f\"K-Fold Few-Shot Learning with {K_FOLD_SIZE} samples\")\n",
    "print(f\"Using Layer: {BEST_LAYER}\")\n",
    "print(f\"\\nSamples: {k_fold_samples}\\n\")\n",
    "\n",
    "# Leave-One-Out Cross Validation\n",
    "loo = LeaveOneOut()\n",
    "operators_list = []\n",
    "bias_list = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(loo.split(k_fold_samples)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold_idx + 1}/{K_FOLD_SIZE}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    fold_train = [k_fold_samples[i] for i in train_idx]\n",
    "    fold_test = [k_fold_samples[i] for i in test_idx]\n",
    "    \n",
    "    # Create few-shot template by prepending training examples\n",
    "    few_shot_examples = \"\\n\".join([\n",
    "        TEMPLATE.format(sample['subject']) + f\" {sample['object']}.\"\n",
    "        for sample in fold_train\n",
    "    ])\n",
    "    few_shot_template = few_shot_examples + \"\\n\" + TEMPLATE\n",
    "    \n",
    "    print(f\"Few-shot template:\\n{few_shot_template}\\n\")\n",
    "    print(f\"Test sample: {fold_test[0]}\")\n",
    "    \n",
    "    # Train operator on this fold\n",
    "    operator = lre.train_lre(fold_train, BEST_LAYER, few_shot_template)\n",
    "    \n",
    "    # Store operator weights and bias\n",
    "    operators_list.append(operator.coef_)\n",
    "    bias_list.append(operator.intercept_)\n",
    "    \n",
    "    # Evaluate on the left-out sample\n",
    "    lre.evaluate(operator, fold_test, BEST_LAYER, few_shot_template)\n",
    "\n",
    "# Average the operators\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AVERAGING OPERATORS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "avg_coef = np.mean(operators_list, axis=0)\n",
    "avg_bias = np.mean(bias_list, axis=0)\n",
    "\n",
    "# Create averaged operator\n",
    "averaged_operator = LinearRegression()\n",
    "averaged_operator.coef_ = avg_coef\n",
    "averaged_operator.intercept_ = avg_bias\n",
    "\n",
    "print(f\"\\nAveraged operator created from {K_FOLD_SIZE} folds\")\n",
    "print(f\"Coefficient shape: {avg_coef.shape}\")\n",
    "print(f\"Bias shape: {avg_bias.shape}\")\n",
    "\n",
    "# Create few-shot template with ALL training samples for consistent evaluation\n",
    "few_shot_examples_all = \"\\n\".join([\n",
    "    TEMPLATE.format(sample['subject']) + f\" {sample['object']}.\"\n",
    "    for sample in k_fold_samples\n",
    "])\n",
    "few_shot_template_all = few_shot_examples_all + \"\\n\" + TEMPLATE\n",
    "\n",
    "# Evaluate averaged operator on all k_fold_samples WITH FEW-SHOT TEMPLATE\n",
    "print(f\"\\nEvaluating averaged operator on all {K_FOLD_SIZE} samples:\")\n",
    "lre.evaluate(averaged_operator, k_fold_samples, BEST_LAYER, few_shot_template_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING ON TEST SET\n",
      "============================================================\n",
      "\n",
      "Few-shot template with 18 training examples\n",
      "\n",
      "Evaluating averaged operator on 12 test samples:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "risk-taking               men             women              ✗ Wrong\n",
      "leadership                men             men              ✓ Correct\n",
      "meticulousness            women           men                ✗ Wrong\n",
      "decisiveness              men             men              ✓ Correct\n",
      "patience                  women           men                ✗ Wrong\n",
      "humility                  women           women            ✓ Correct\n",
      "adventurousness           men             men              ✓ Correct\n",
      "independence              men             men              ✓ Correct\n",
      "generosity                women           men                ✗ Wrong\n",
      "empathy                   women           women            ✓ Correct\n",
      "compassion                women           women            ✓ Correct\n",
      "intuition                 women           women            ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      8/12 (66.67%)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct': 8, 'total': 12, 'faithfulness': 0.6666666666666666}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate averaged operator on test set\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Create few-shot template with all training examples\n",
    "few_shot_examples_full = \"\\n\".join([\n",
    "    TEMPLATE.format(sample['subject']) + f\" {sample['object']}.\"\n",
    "    for sample in train_data\n",
    "])\n",
    "few_shot_template_full = few_shot_examples_full + \"\\n\" + TEMPLATE\n",
    "\n",
    "print(f\"\\nFew-shot template with {len(train_data)} training examples\")\n",
    "print(f\"\\nEvaluating averaged operator on {len(test_data)} test samples:\")\n",
    "lre.evaluate(averaged_operator, test_data, BEST_LAYER, few_shot_template_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Layer-by-Layer Experiment\n",
    "\n",
    "We'll train an LRE operator for each layer and compare faithfulness scores.\n",
    "This helps us understand:\n",
    "- Where in the network relational knowledge emerges\n",
    "- Whether shallow or deep layers are more linear for this task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 12 layers: ['model.layers.4', 'model.layers.5', 'model.layers.6', 'model.layers.7', 'model.layers.8', 'model.layers.9', 'model.layers.10', 'model.layers.11', 'model.layers.12', 'model.layers.13', 'model.layers.14', 'model.layers.15']\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 4\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 4:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             women              ✗ Wrong\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           women            ✓ Correct\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             men              ✓ Correct\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             women              ✗ Wrong\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      13/16 (81.25%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 5\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 5:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           women            ✓ Correct\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             women              ✗ Wrong\n",
      "================================================================================\n",
      "Faithfulness Score:                      13/16 (81.25%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 6\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 6:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             women              ✗ Wrong\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             men              ✓ Correct\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             men              ✓ Correct\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      14/16 (87.50%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 7\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 7:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             men              ✓ Correct\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      14/16 (87.50%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 8\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 8:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             men              ✓ Correct\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      14/16 (87.50%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 9\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 9:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      13/16 (81.25%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 10\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 10:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             men              ✓ Correct\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      14/16 (87.50%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 11\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 11:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             men              ✓ Correct\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      14/16 (87.50%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 12\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 12:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             men              ✓ Correct\n",
      "chemistry                 men             women              ✗ Wrong\n",
      "business                  men             men              ✓ Correct\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      14/16 (87.50%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 13\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 13:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             men              ✓ Correct\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             women              ✗ Wrong\n",
      "business                  men             men              ✓ Correct\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      13/16 (81.25%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 14\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 14:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             women              ✗ Wrong\n",
      "environmental science     women           men                ✗ Wrong\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             women              ✗ Wrong\n",
      "================================================================================\n",
      "Faithfulness Score:                      11/16 (68.75%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING LAYER 15\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating Layer 15:\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             women              ✗ Wrong\n",
      "environmental science     women           women            ✓ Correct\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             women              ✗ Wrong\n",
      "================================================================================\n",
      "Faithfulness Score:                      12/16 (75.00%)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LAYER COMPARISON SUMMARY\n",
      "================================================================================\n",
      "Layer 4: Faithfulness = 0.8125\n",
      "Layer 5: Faithfulness = 0.8125\n",
      "Layer 6: Faithfulness = 0.8750\n",
      "Layer 7: Faithfulness = 0.8750\n",
      "Layer 8: Faithfulness = 0.8750\n",
      "Layer 9: Faithfulness = 0.8125\n",
      "Layer 10: Faithfulness = 0.8750\n",
      "Layer 11: Faithfulness = 0.8750\n",
      "Layer 12: Faithfulness = 0.8750\n",
      "Layer 13: Faithfulness = 0.8125\n",
      "Layer 14: Faithfulness = 0.6875\n",
      "Layer 15: Faithfulness = 0.7500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = {}\n",
    "faithfulness_scores = {}\n",
    "\n",
    "# Expand layer range to include layers 8-15\n",
    "LAYERS_TO_TEST = [f\"model.layers.{i}\" for i in range(4, 16)]\n",
    "print(f\"Testing {len(LAYERS_TO_TEST)} layers: {LAYERS_TO_TEST}\")\n",
    "\n",
    "for layer_name in LAYERS_TO_TEST:\n",
    "    layer_num = layer_name.split(\".\")[-1]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTING LAYER {layer_num}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train LRE operator for this layer\n",
    "    operator = lre.train_lre(train_data, layer_name, TEMPLATE)\n",
    "    \n",
    "    # Evaluate and capture faithfulness score\n",
    "    print(f\"\\nEvaluating Layer {layer_num}:\")\n",
    "    eval_results = lre.evaluate(operator, test_data, layer_name, TEMPLATE)\n",
    "    \n",
    "    # Store results\n",
    "    results[layer_name] = operator\n",
    "    faithfulness_scores[layer_name] = eval_results.get('faithfulness', 0)\n",
    "\n",
    "# Create faithfulness heatmap\n",
    "layer_numbers = [int(layer.split(\".\")[-1]) for layer in LAYERS_TO_TEST]\n",
    "faithfulness_values = [faithfulness_scores[layer] for layer in LAYERS_TO_TEST]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(layer_numbers, faithfulness_values, color='steelblue')\n",
    "ax.set_xlabel('Faithfulness Score')\n",
    "ax.set_ylabel('Layer Number')\n",
    "ax.set_title('LRE Faithfulness by Layer')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LAYER COMPARISON SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "for layer in LAYERS_TO_TEST:\n",
    "    layer_num = layer.split(\".\")[-1]\n",
    "    print(f\"Layer {layer_num}: Faithfulness = {faithfulness_scores[layer]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Additional Experiment: Different Prompt Template\n",
    "\n",
    "Let's also test whether a different prompt format affects results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTING ALTERNATIVE PROMPT TEMPLATE\n",
      "Template: 'Most {} majors are'\n",
      "================================================================================\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             women              ✗ Wrong\n",
      "environmental science     women           women            ✓ Correct\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      13/16 (81.25%)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct': 13, 'total': 16, 'faithfulness': 0.8125}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try an alternative template\n",
    "ALT_TEMPLATE = \"Most {} majors are\"\n",
    "BEST_LAYER = \"model.layers.15\"  # Based on results above, adjust if needed\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ALTERNATIVE PROMPT TEMPLATE\")\n",
    "print(f\"Template: '{ALT_TEMPLATE}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "operator_alt = lre.train_lre(train_data, BEST_LAYER, ALT_TEMPLATE)\n",
    "lre.evaluate(operator_alt, test_data, BEST_LAYER, ALT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STANDARD LINEAR REGRESSION (No Leave-One-Out)\n",
      "============================================================\n",
      "Training on 22 samples\n",
      "Using Layer: model.layers.15\n",
      "Extracting training representations...\n",
      "Solving Linear Regression...\n",
      "\n",
      "Evaluating on training data (22 samples):\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "law                       men             men              ✓ Correct\n",
      "culinary arts             women           women            ✓ Correct\n",
      "biology                   women           women            ✓ Correct\n",
      "public relations          women           women            ✓ Correct\n",
      "history                   men             men              ✓ Correct\n",
      "mechanical engineering    men             men              ✓ Correct\n",
      "sociology                 women           women            ✓ Correct\n",
      "social work               women           women            ✓ Correct\n",
      "communications            women           women            ✓ Correct\n",
      "classical studies         women           women            ✓ Correct\n",
      "interior design           women           women            ✓ Correct\n",
      "psychology                women           women            ✓ Correct\n",
      "physics                   men             men              ✓ Correct\n",
      "architecture              men             men              ✓ Correct\n",
      "education                 women           women            ✓ Correct\n",
      "human resources           women           women            ✓ Correct\n",
      "literature                women           women            ✓ Correct\n",
      "fine arts                 women           women            ✓ Correct\n",
      "philosophy                men             men              ✓ Correct\n",
      "pharmacy                  women           women            ✓ Correct\n",
      "statistics                men             men              ✓ Correct\n",
      "astronomy                 men             men              ✓ Correct\n",
      "================================================================================\n",
      "Faithfulness Score:                      22/22 (100.00%)\n",
      "================================================================================\n",
      "\n",
      "Evaluating on test data (16 samples):\n",
      "\n",
      "================================================================================\n",
      "                               EVALUATION RESULTS                               \n",
      "================================================================================\n",
      "Subject                   Expected        LRE Prediction      Status\n",
      "--------------------------------------------------------------------------------\n",
      "nursing                   women           women            ✓ Correct\n",
      "geology                   men             men              ✓ Correct\n",
      "accounting                men             women              ✗ Wrong\n",
      "environmental science     women           women            ✓ Correct\n",
      "computer science          men             men              ✓ Correct\n",
      "anthropology              women           women            ✓ Correct\n",
      "marine biology            women           women            ✓ Correct\n",
      "political science         men             women              ✗ Wrong\n",
      "chemistry                 men             men              ✓ Correct\n",
      "business                  men             women              ✗ Wrong\n",
      "mathematics               men             men              ✓ Correct\n",
      "electrical engineering    men             men              ✓ Correct\n",
      "fashion design            women           women            ✓ Correct\n",
      "graphic design            women           women            ✓ Correct\n",
      "engineering               men             men              ✓ Correct\n",
      "economics                 men             women              ✗ Wrong\n",
      "================================================================================\n",
      "Faithfulness Score:                      12/16 (75.00%)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'correct': 12, 'total': 16, 'faithfulness': 0.75}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Linear Regression without Leave-One-Out\n",
    "print(f\"{'='*60}\")\n",
    "print(\"STANDARD LINEAR REGRESSION (No Leave-One-Out)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training on {len(train_data)} samples\")\n",
    "print(f\"Using Layer: {BEST_LAYER}\")\n",
    "\n",
    "# Train operator on all training data\n",
    "operator_standard = lre.train_lre(train_data, BEST_LAYER, TEMPLATE)\n",
    "\n",
    "# Evaluate on training data\n",
    "print(f\"\\nEvaluating on training data ({len(train_data)} samples):\")\n",
    "lre.evaluate(operator_standard, train_data, BEST_LAYER, TEMPLATE)\n",
    "\n",
    "# Evaluate on test data\n",
    "print(f\"\\nEvaluating on test data ({len(test_data)} samples):\")\n",
    "lre.evaluate(operator_standard, test_data, BEST_LAYER, TEMPLATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lre-experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
